{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "70wW5hoAri75"
      },
      "source": [
        "# Fetch Recommendations"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f3-tqGK3O-SF"
      },
      "source": [
        "Notebook to access and fetch recommendations from the database"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MiQiBw3ZPB48"
      },
      "source": [
        "## Setup\n",
        "\n",
        "You will need to restart the runtime after running this cell as the numpy version is changed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLomSCH7hpWr"
      },
      "outputs": [],
      "source": [
        "!pip install numpy==1.23.2\n",
        "!pip install transformers==4.28.0\n",
        "!pip install -U sentence-transformers\n",
        "!pip install datasets\n",
        "!pip install torch\n",
        "!pip install -qU pinecone-client[grpc]\n",
        "!pip install Cython"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eZYXCEqjsXeL"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqxO-2hQhtsv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pinecone\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "PINECONE_API_KEY = \"\"\n",
        "PINECONE_ENV = \"\"\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,\n",
        "    environment=PINECONE_ENV\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjguFbZojKPA"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yELStG5Ps4KZ"
      },
      "source": [
        "### Connecting to the Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZmp0IB0h1fd"
      },
      "outputs": [],
      "source": [
        "index_name = \"reviewer-assignment\"    # Replace with your index name\n",
        "index = pinecone.GRPCIndex(index_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QyBKdFwGPG0G"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jitH1U8as6Zo"
      },
      "source": [
        "### Model Initiation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Io88NrP-iDKH"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "m_tokenizer = AutoTokenizer.from_pretrained(\"biodatlab/MIReAD-Neuro\")\n",
        "m_model = BertForSequenceClassification.from_pretrained(\"biodatlab/MIReAD-Neuro\")\n",
        "miread_bundle = (m_tokenizer,m_model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yCyrkdB_s8fg"
      },
      "source": [
        "### Create Embedding from Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tllBM9Ouh4UG"
      },
      "outputs": [],
      "source": [
        "def create_miread_embed(text,bundle):\n",
        "  tokenizer = bundle[0]\n",
        "  model = bundle[1]\n",
        "  model.cuda()\n",
        "  tokens = tokenizer(text,\n",
        "                   max_length=512,\n",
        "                   padding=True,\n",
        "                   truncation=True,\n",
        "                   return_tensors=\"pt\"\n",
        "                  )\n",
        "  cuda = torch.device('cuda')\n",
        "  tokens = tokens.to(cuda)\n",
        "  with torch.no_grad():\n",
        "    out = model.bert(**tokens)\n",
        "    feature = out.last_hidden_state[:, 0, :]\n",
        "  return feature.cpu()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x5CUxQFns_oW"
      },
      "source": [
        "### Function to query the database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gM5OkBl_nPAQ"
      },
      "outputs": [],
      "source": [
        "def get_matches(query,k=10,include_metadata=True,mode='a'):\n",
        "  \"\"\"\n",
        "  Queries the index to get matches from the database and prints them.\n",
        "\n",
        "          Parameters:\n",
        "                query (int) : containing the abstract\n",
        "                k (int) : fetches best 'k' results\n",
        "                include_metadata (bool) : fetches the title and abstract of the match as well\n",
        "                mode (string) : what to recommend. 'a' for abstracts, 'j' for journals, 'n' for author names\n",
        "\n",
        "          Returns:\n",
        "                matches : The actual object returned by the index.query() method, if you require any additional data about the matches.\n",
        "  \"\"\"\n",
        "  encoded_query = create_miread_embed(query,miread_bundle)\n",
        "  # Get matches from the pinecone database\n",
        "  matches = index.query(encoded_query.tolist()[0],top_k=k,include_metadata=include_metadata)\n",
        "  # Buckets to store results of each mode\n",
        "  j_bucket = {'None':0}\n",
        "  n_bucket = {'None':0}\n",
        "  for i,match in enumerate(matches['matches']):\n",
        "    if 'j' in mode:\n",
        "      if match['metadata']['journal'] not in j_bucket:\n",
        "        j_bucket[match['metadata']['journal']] = match['score']\n",
        "      else:\n",
        "        j_bucket[match['metadata']['journal']] += match['score']\n",
        "    if 'n' in mode:\n",
        "      authors = eval(match['metadata']['author'])\n",
        "      if authors and authors[0] not in n_bucket:\n",
        "        n_bucket[authors[0]] = match['score']\n",
        "      elif authors:\n",
        "        n_bucket[authors[0]] += match['score']\n",
        "      else:\n",
        "        n_bucket['None'] += match['score']\n",
        "    if 'a' in mode:\n",
        "      print(f\"Match {i+1}\")\n",
        "      print(f\"id : {match['id']}\")\n",
        "      print(f\"score : {match['score']}\")\n",
        "      print(f\"title : {match['metadata']['identifier']}\")\n",
        "      print(f\"abstract: {match['metadata']['abstract']}\")\n",
        "      print(f\"journal: {match['metadata']['journal']}\")\n",
        "      print(f\"author: {match['metadata']['author']}\")\n",
        "      print('----------------------------------------------------------------------------------------------------------------------------')\n",
        "  # Sort results\n",
        "  j_results = sorted([(key,val) for key,val in j_bucket.items()],key= lambda x : x[1],reverse=True)\n",
        "  n_results = sorted([(key,val) for key,val in n_bucket.items()],key= lambda x : x[1],reverse=True)\n",
        "  if 'j' in mode:\n",
        "    print(f\"{mode.upper()} Results :\")\n",
        "    results = j_results\n",
        "  elif 'n' in mode:\n",
        "    results = n_results\n",
        "  if results:\n",
        "    for i, item in enumerate(results):\n",
        "      if item[0] != 'None':\n",
        "        print(f\"{i}) '{item[0]}' with score {item[1]}\")\n",
        "      else:\n",
        "        print(f\"Some similar matches didn't have the required data. The score was {item[1]} \")\n",
        "  return matches"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qGUPGSl2MCYo"
      },
      "source": [
        "## Sample Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IWdtYcIlmDv"
      },
      "outputs": [],
      "source": [
        "query = \"Insert your abstract here.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3tIz90DnqT0"
      },
      "outputs": [],
      "source": [
        "matches = get_matches(query,k=30,include_metadata=True,mode='j')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
